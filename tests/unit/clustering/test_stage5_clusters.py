#!/usr/bin/env python3
"""
Test cluster formation and analysis.
"""

import asyncio
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Any

from pavel.clustering.dynamic_cluster_detector import DynamicClusterDetector, IssueCategory
from pavel.core.app_config import get_default_app_id


def create_test_embeddings(reviews: List[Dict[str, Any]]) -> np.ndarray:
    """Create simple test embeddings using TF-IDF."""
    from sklearn.feature_extraction.text import TfidfVectorizer
    
    texts = [r['content'] for r in reviews]
    vectorizer = TfidfVectorizer(max_features=100, stop_words='english')
    embeddings = vectorizer.fit_transform(texts).toarray()
    
    return embeddings


async def test_cluster_formation():
    """Test cluster formation with different review types."""
    print("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –ö–õ–ê–°–¢–ï–†–û–í")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –æ—Ç–∑—ã–≤—ã —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏
    base_time = datetime.now()
    reviews = [
        # –ö–ª–∞—Å—Ç–µ—Ä 1: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (crashes)
        {'review_id': '1', 'content': 'App crashes constantly when I try to book', 'rating': 1, 'created_at': base_time},
        {'review_id': '2', 'content': 'Keeps crashing during payment process', 'rating': 1, 'created_at': base_time},
        {'review_id': '3', 'content': 'Crashes every time I open the app', 'rating': 1, 'created_at': base_time},
        
        # –ö–ª–∞—Å—Ç–µ—Ä 2: –ü—Ä–æ–±–ª–µ–º—ã —Å –æ–ø–ª–∞—Ç–æ–π (payment)
        {'review_id': '4', 'content': 'Payment failed multiple times, cannot pay', 'rating': 2, 'created_at': base_time},
        {'review_id': '5', 'content': 'Billing error, charged twice for same ride', 'rating': 1, 'created_at': base_time},
        {'review_id': '6', 'content': 'Payment system is broken, need refund', 'rating': 1, 'created_at': base_time},
        
        # –ö–ª–∞—Å—Ç–µ—Ä 3: –ü—Ä–æ–±–ª–µ–º—ã —Å –≤–æ–¥–∏—Ç–µ–ª—è–º–∏ (drivers)
        {'review_id': '7', 'content': 'Driver was rude and unprofessional service', 'rating': 2, 'created_at': base_time},
        {'review_id': '8', 'content': 'Bad driver behavior, very unpleasant experience', 'rating': 1, 'created_at': base_time},
        {'review_id': '9', 'content': 'Driver arrived late and was not polite', 'rating': 2, 'created_at': base_time},
        
        # –ö–ª–∞—Å—Ç–µ—Ä 4: –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã (positive)
        {'review_id': '10', 'content': 'Great app, fast service, amazing experience', 'rating': 5, 'created_at': base_time},
        {'review_id': '11', 'content': 'Excellent drivers, always on time and polite', 'rating': 5, 'created_at': base_time},
        {'review_id': '12', 'content': 'Perfect app, easy to use, highly recommend', 'rating': 5, 'created_at': base_time},
        
        # –ö–ª–∞—Å—Ç–µ—Ä 5: UI/UX –ø—Ä–æ–±–ª–µ–º—ã (interface)
        {'review_id': '13', 'content': 'Interface is confusing, hard to navigate', 'rating': 2, 'created_at': base_time},
        {'review_id': '14', 'content': 'UI design is terrible, cannot find buttons', 'rating': 2, 'created_at': base_time},
        {'review_id': '15', 'content': 'App interface needs complete redesign', 'rating': 2, 'created_at': base_time},
    ]
    
    print(f"üìù –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(reviews)} –æ—Ç–∑—ã–≤–∞—Ö:")
    print("   üêõ Crashes (3 –æ—Ç–∑—ã–≤–∞)")
    print("   üí≥ Payment issues (3 –æ—Ç–∑—ã–≤–∞)")  
    print("   üöó Driver problems (3 –æ—Ç–∑—ã–≤–∞)")
    print("   üòä Positive reviews (3 –æ—Ç–∑—ã–≤–∞)")
    print("   üñ•Ô∏è UI/UX issues (3 –æ—Ç–∑—ã–≤–∞)")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings
    print("\nüß† –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings...")
    embeddings = create_test_embeddings(reviews)
    print(f"   –†–∞–∑–º–µ—Ä embeddings: {embeddings.shape}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    detector = DynamicClusterDetector(
        n_clusters_range=(3, 7),  # –û–∂–∏–¥–∞–µ–º 5 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        min_cluster_size=2,       # –ú–∏–Ω–∏–º—É–º 2 –æ—Ç–∑—ã–≤–∞ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
        significance_threshold=1.5  # –ë–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
    print("\nüéØ –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é...")
    anomalies = detector.detect_anomalies(reviews, embeddings, base_time)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò:")
    print(f"   üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {len(anomalies)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
    if detector.cluster_baselines:
        print(f"   üìà –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(detector.cluster_baselines)}")
        
        for cluster_id, baseline in detector.cluster_baselines.items():
            print(f"\n   üè∑Ô∏è –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}:")
            print(f"      –†–∞–∑–º–µ—Ä: {baseline['size']}")
            print(f"      –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {baseline['mean_rating']:.1f}")
            print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {baseline.get('category', IssueCategory.UNKNOWN).value}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç—Ä–µ–Ω–¥—ã
    trends = detector.get_cluster_trends()
    if trends:
        print(f"\nüìà –¢–†–ï–ù–î–´ –ö–õ–ê–°–¢–ï–†–û–í:")
        for cluster_id, trend in trends.items():
            print(f"   –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {trend['size_trend']} ({trend['size_change_pct']:+.1f}%)")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
    if anomalies:
        print(f"\n‚ö†Ô∏è –ù–ê–ô–î–ï–ù–ù–´–ï –ê–ù–û–ú–ê–õ–ò–ò:")
        for i, anomaly in enumerate(anomalies[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            print(f"   {i+1}. {anomaly.anomaly_type} –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ {anomaly.cluster_id}")
            print(f"      –°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å: {anomaly.severity:.2f}")
            print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {anomaly.category.value}")
            print(f"      –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {anomaly.explanation}")
    
    return len(detector.cluster_baselines) >= 3  # –£—Å–ø–µ—Ö –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –º–∏–Ω–∏–º—É–º 3 –∫–ª–∞—Å—Ç–µ—Ä–∞


async def test_real_clustering():
    """Test clustering with real embeddings on fewer reviews."""
    print("\nüåü –¢–ï–°–¢ –° –†–ï–ê–õ–¨–ù–´–ú–ò EMBEDDINGS")
    print("=" * 50)
    
    from sklearn.cluster import DBSCAN, KMeans
    
    # –°–æ–∑–¥–∞–µ–º –æ—Ç–∑—ã–≤—ã —Å —á–µ—Ç–∫–∏–º–∏ —Ç–µ–º–∞–º–∏
    reviews = [
        {'content': 'app crashes all the time', 'rating': 1},
        {'content': 'constant crashes, unusable', 'rating': 1}, 
        {'content': 'payment failed twice', 'rating': 1},
        {'content': 'billing issues, wrong charges', 'rating': 1},
        {'content': 'great service, fast rides', 'rating': 5},
        {'content': 'excellent experience, recommend', 'rating': 5},
    ]
    
    # TF-IDF embeddings
    embeddings = create_test_embeddings(reviews)
    
    print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤...")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    print("\nüîÑ DBSCAN –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è:")
    dbscan = DBSCAN(eps=0.5, min_samples=2, metric='cosine')
    dbscan_labels = dbscan.fit_predict(embeddings)
    
    clusters = {}
    for i, label in enumerate(dbscan_labels):
        if label not in clusters:
            clusters[label] = []
        clusters[label].append((i, reviews[i]['content'][:50]))
    
    for cluster_id, items in clusters.items():
        if cluster_id == -1:
            print(f"   üö´ –®—É–º ({len(items)} –æ—Ç–∑—ã–≤–æ–≤)")
        else:
            print(f"   üè∑Ô∏è –ö–ª–∞—Å—Ç–µ—Ä {cluster_id} ({len(items)} –æ—Ç–∑—ã–≤–æ–≤):")
            for idx, content in items:
                print(f"      ‚Ä¢ {content}...")
    
    print("\nüìä K-Means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (k=3):")
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans_labels = kmeans.fit_predict(embeddings)
    
    kmeans_clusters = {}
    for i, label in enumerate(kmeans_labels):
        if label not in kmeans_clusters:
            kmeans_clusters[label] = []
        kmeans_clusters[label].append((i, reviews[i]['content'][:50]))
    
    for cluster_id, items in kmeans_clusters.items():
        print(f"   üè∑Ô∏è –ö–ª–∞—Å—Ç–µ—Ä {cluster_id} ({len(items)} –æ—Ç–∑—ã–≤–æ–≤):")
        for idx, content in items:
            print(f"      ‚Ä¢ {content}...")
    
    return True


async def main():
    """Main function to test clustering."""
    print("üß™ PAVEL CLUSTER ANALYSIS TEST")
    print("=" * 50)
    
    # Test 1: Basic cluster formation
    basic_success = await test_cluster_formation()
    
    # Test 2: Real clustering methods
    real_success = await test_real_clustering()
    
    print("\n" + "=" * 50)
    if basic_success and real_success:
        print("‚úÖ –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –†–ê–ë–û–¢–ê–ï–¢ –ö–û–†–†–ï–ö–¢–ù–û!")
        print("\nüéØ –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
        print("   ‚úì –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        print("   ‚úì –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–µ–º–∞–º")
        print("   ‚úì –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ vs –ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ")
        print("   ‚úì –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        print("   ‚úì –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∏–Ω–∞–º–∏–∫–µ")
    else:
        print("‚ùå –ù—É–∂–Ω—ã –¥–æ—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
    

if __name__ == "__main__":
    asyncio.run(main())