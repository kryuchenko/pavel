#!/usr/bin/env python3
"""
Test alternative language detection methods for Kazakh language.

Compares different libraries and approaches for Kazakh language detection.
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from pavel.core.logger import get_logger

logger = get_logger(__name__)

def test_langdetect():
    """Test standard langdetect library"""
    try:
        from langdetect import detect, detect_langs
        logger.info("Testing langdetect library:")
        
        texts = [
            "Ð‘Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ° Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹, Ð¶Ñ‹Ð»Ð´Ð°Ð¼ Ð¶Ó™Ð½Ðµ Ñ‹Ò£Ò“Ð°Ð¹Ð»Ñ‹.",
            "Ó¨Ñ‚Ðµ ÐºÐµÑ€ÐµÐ¼ÐµÑ‚ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°! Ð–Ò±Ð¼Ñ‹Ñ Ñ–ÑÑ‚ÐµÐ¹Ð´Ñ– Ñ‚Ð°Ð¼Ð°ÑˆÐ°.",
            "Ð–Ð°Ò›ÑÑ‹ Ð°Ò›ÑˆÐ° Ò¯Ð½ÐµÐ¼Ð´ÐµÐ¹Ñ‚Ñ–Ð½ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°. Ò°ÑÑ‹Ð½Ð°Ð¼Ñ‹Ð½!",
            "ÐœÐµÐ½ Ð±Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°Ð½Ñ‹ Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹ ÐºÓ©Ñ€ÐµÐ¼Ñ–Ð½.",
        ]
        
        for text in texts:
            try:
                result = detect(text)
                langs = detect_langs(text)
                logger.info(f"  '{text[:30]}...' â†’ {result} {[f'{l.lang}:{l.prob:.2f}' for l in langs[:3]]}")
            except Exception as e:
                logger.info(f"  '{text[:30]}...' â†’ ERROR: {e}")
                
        return True
    except ImportError:
        logger.warning("langdetect not available")
        return False

def test_polyglot():
    """Test polyglot library (if available)"""
    try:
        from polyglot.detect import Detector
        logger.info("\nTesting polyglot library:")
        
        texts = [
            "Ð‘Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ° Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹, Ð¶Ñ‹Ð»Ð´Ð°Ð¼ Ð¶Ó™Ð½Ðµ Ñ‹Ò£Ò“Ð°Ð¹Ð»Ñ‹.",
            "Ó¨Ñ‚Ðµ ÐºÐµÑ€ÐµÐ¼ÐµÑ‚ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°! Ð–Ò±Ð¼Ñ‹Ñ Ñ–ÑÑ‚ÐµÐ¹Ð´Ñ– Ñ‚Ð°Ð¼Ð°ÑˆÐ°.",
        ]
        
        for text in texts:
            try:
                detector = Detector(text)
                logger.info(f"  '{text[:30]}...' â†’ {detector.language.code} ({detector.language.confidence:.2f})")
            except Exception as e:
                logger.info(f"  '{text[:30]}...' â†’ ERROR: {e}")
                
        return True
    except ImportError:
        logger.info("polyglot not available (pip install polyglot)")
        return False

def test_langid():
    """Test langid library"""
    try:
        import langid
        logger.info("\nTesting langid library:")
        
        texts = [
            "Ð‘Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ° Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹, Ð¶Ñ‹Ð»Ð´Ð°Ð¼ Ð¶Ó™Ð½Ðµ Ñ‹Ò£Ò“Ð°Ð¹Ð»Ñ‹.",
            "Ó¨Ñ‚Ðµ ÐºÐµÑ€ÐµÐ¼ÐµÑ‚ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°! Ð–Ò±Ð¼Ñ‹Ñ Ñ–ÑÑ‚ÐµÐ¹Ð´Ñ– Ñ‚Ð°Ð¼Ð°ÑˆÐ°.",
            "Ð–Ð°Ò›ÑÑ‹ Ð°Ò›ÑˆÐ° Ò¯Ð½ÐµÐ¼Ð´ÐµÐ¹Ñ‚Ñ–Ð½ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°. Ò°ÑÑ‹Ð½Ð°Ð¼Ñ‹Ð½!",
        ]
        
        for text in texts:
            try:
                lang, conf = langid.classify(text)
                logger.info(f"  '{text[:30]}...' â†’ {lang} ({conf:.2f})")
            except Exception as e:
                logger.info(f"  '{text[:30]}...' â†’ ERROR: {e}")
                
        return True
    except ImportError:
        logger.info("langid not available (pip install langid)")
        return False

def test_textblob():
    """Test TextBlob library"""
    try:
        from textblob import TextBlob
        logger.info("\nTesting TextBlob library:")
        
        texts = [
            "Ð‘Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ° Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹, Ð¶Ñ‹Ð»Ð´Ð°Ð¼ Ð¶Ó™Ð½Ðµ Ñ‹Ò£Ò“Ð°Ð¹Ð»Ñ‹.",
            "Ó¨Ñ‚Ðµ ÐºÐµÑ€ÐµÐ¼ÐµÑ‚ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°! Ð–Ò±Ð¼Ñ‹Ñ Ñ–ÑÑ‚ÐµÐ¹Ð´Ñ– Ñ‚Ð°Ð¼Ð°ÑˆÐ°.",
        ]
        
        for text in texts:
            try:
                blob = TextBlob(text)
                lang = blob.detect_language()
                logger.info(f"  '{text[:30]}...' â†’ {lang}")
            except Exception as e:
                logger.info(f"  '{text[:30]}...' â†’ ERROR: {e}")
                
        return True
    except ImportError:
        logger.info("TextBlob not available (pip install textblob)")
        return False

def test_googletrans():
    """Test Google Translate API detection"""
    try:
        from googletrans import Translator
        logger.info("\nTesting Google Translate detection:")
        
        translator = Translator()
        texts = [
            "Ð‘Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ° Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹, Ð¶Ñ‹Ð»Ð´Ð°Ð¼ Ð¶Ó™Ð½Ðµ Ñ‹Ò£Ò“Ð°Ð¹Ð»Ñ‹.",
            "Ó¨Ñ‚Ðµ ÐºÐµÑ€ÐµÐ¼ÐµÑ‚ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°! Ð–Ò±Ð¼Ñ‹Ñ Ñ–ÑÑ‚ÐµÐ¹Ð´Ñ– Ñ‚Ð°Ð¼Ð°ÑˆÐ°.",
        ]
        
        for text in texts:
            try:
                result = translator.detect(text)
                logger.info(f"  '{text[:30]}...' â†’ {result.lang} ({result.confidence:.2f})")
            except Exception as e:
                logger.info(f"  '{text[:30]}...' â†’ ERROR: {e}")
                
        return True
    except ImportError:
        logger.info("googletrans not available (pip install googletrans==4.0.0-rc1)")
        return False

def test_fasttext():
    """Test FastText language identification"""
    try:
        import fasttext
        logger.info("\nTesting FastText library:")
        
        # Download model if needed
        model_path = "lid.176.bin"
        if not os.path.exists(model_path):
            logger.info("Downloading FastText language identification model...")
            import urllib.request
            urllib.request.urlretrieve("https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin", model_path)
        
        model = fasttext.load_model(model_path)
        
        texts = [
            "Ð‘Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ° Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹, Ð¶Ñ‹Ð»Ð´Ð°Ð¼ Ð¶Ó™Ð½Ðµ Ñ‹Ò£Ò“Ð°Ð¹Ð»Ñ‹.",
            "Ó¨Ñ‚Ðµ ÐºÐµÑ€ÐµÐ¼ÐµÑ‚ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°! Ð–Ò±Ð¼Ñ‹Ñ Ñ–ÑÑ‚ÐµÐ¹Ð´Ñ– Ñ‚Ð°Ð¼Ð°ÑˆÐ°.",
            "Ð–Ð°Ò›ÑÑ‹ Ð°Ò›ÑˆÐ° Ò¯Ð½ÐµÐ¼Ð´ÐµÐ¹Ñ‚Ñ–Ð½ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°. Ò°ÑÑ‹Ð½Ð°Ð¼Ñ‹Ð½!",
        ]
        
        for text in texts:
            try:
                predictions = model.predict(text.replace('\n', ' '), k=3)
                langs = [lang.replace('__label__', '') for lang in predictions[0]]
                scores = predictions[1]
                result = list(zip(langs, scores))
                logger.info(f"  '{text[:30]}...' â†’ {result}")
            except Exception as e:
                logger.info(f"  '{text[:30]}...' â†’ ERROR: {e}")
                
        return True
    except ImportError:
        logger.info("fasttext not available (pip install fasttext)")
        return False

def test_spacy():
    """Test spaCy language detection"""
    try:
        import spacy
        from spacy.lang.kk import Kazakh  # Check if Kazakh is supported
        
        logger.info("\nTesting spaCy Kazakh support:")
        logger.info("  spaCy has Kazakh language class available!")
        
        # Check available models
        logger.info("  Available spaCy models:")
        import subprocess
        try:
            result = subprocess.run(['python', '-m', 'spacy', 'info'], capture_output=True, text=True)
            if 'kk' in result.stdout:
                logger.info("  Kazakh model found!")
            else:
                logger.info("  No Kazakh model installed")
        except:
            logger.info("  Could not check spaCy models")
            
        return True
    except ImportError:
        logger.info("spaCy not available (pip install spacy)")
        return False

def test_enhanced_patterns():
    """Test our enhanced pattern-based detection for Kazakh"""
    import re
    
    logger.info("\nTesting enhanced Kazakh patterns:")
    
    # More comprehensive Kazakh patterns
    kazakh_patterns = [
        # Kazakh-specific letters (must be present)
        re.compile(r'[Ó™Ò“Ò›Ò£Ó©Ò±Ò¯Ò»Ñ–]', re.IGNORECASE),
        
        # Kazakh-specific letter combinations
        re.compile(r'(Ò“[Ð°Ó™ÐµÐ¸Ð¾Ó©ÑƒÒ¯Ñ‹Ñ–]|Ò›[Ð°Ó™ÐµÐ¸Ð¾Ó©ÑƒÒ¯Ñ‹Ñ–]|Ò£[Ð°Ó™ÐµÐ¸Ð¾Ó©ÑƒÒ¯Ñ‹Ñ–])', re.IGNORECASE),
        re.compile(r'(Ó™[Ð¹Ð»Ð¼Ð½Ñ€ÑÑ‚Ñ‚]|Ó©[Ð¹Ð»Ð¼Ð½Ñ€ÑÑ‚Ñ‚]|Ò±[Ð¹Ð»Ð¼Ð½Ñ€ÑÑ‚Ñ‚]|Ò¯[Ð¹Ð»Ð¼Ð½Ñ€ÑÑ‚Ñ‚])', re.IGNORECASE),
        
        # Common Kazakh words with unique letters
        re.compile(r'\b(Ð±Ò±Ð»|Ð¶Ó™Ð½Ðµ|Ò¯ÑˆÑ–Ð½|Ð¶Ð°Ò›ÑÑ‹|Ð¶Ð°Ð¼Ð°Ð½|Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°|Ó©Ñ‚Ðµ|ÐºÐµÑ€ÐµÐ¼ÐµÑ‚|Ò±ÑÑ‹Ð½Ð°Ð¼Ñ‹Ð½|Ò›Ð°Ñ€Ð¶Ñ‹|Ð°Ò›ÑˆÐ°)\b', re.IGNORECASE),
        
        # Kazakh morphology patterns (suffixes)
        re.compile(r'(Ò“Ñ‹|Ò“Ñ–|Ò“Ñƒ|Ò“Ò¯|Ò›Ñ‹|Ò›Ñ–|Ò›Ñƒ|Ò›Ò¯|Ò£Ñ‹|Ò£Ñ–|Ò£Ñƒ|Ò£Ò¯)', re.IGNORECASE),
        re.compile(r'(ÑˆÑ‹|ÑˆÑ–|ÑˆÑƒ|ÑˆÒ¯|ÑÑ‹|ÑÑ–|ÑÑƒ|ÑÒ¯)', re.IGNORECASE),
        
        # Typical Kazakh sentence patterns
        re.compile(r'\b\w+[Ó™Ó©Ò±Ò¯]\w*\s+\w+[Ò“Ò›Ò£]\w*\b', re.IGNORECASE),
    ]
    
    # Russian patterns for comparison
    russian_patterns = [
        # Russian-only patterns (no Kazakh letters)
        re.compile(r'\b(ÑÑ‚Ð¾|Ñ‡Ñ‚Ð¾|ÐºÐ°Ðº|Ð²ÑÐµ|Ð´Ð»Ñ|Ð¸Ð»Ð¸|Ð¼Ð¾Ð¶ÐµÑ‚|Ð¾Ñ‡ÐµÐ½ÑŒ|Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾|Ð¿Ð»Ð¾Ñ…Ð¾|Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ|ÑÐ¿Ð°ÑÐ¸Ð±Ð¾)\b', re.IGNORECASE),
        re.compile(r'[^Ó™Ò“Ò›Ò£Ó©Ò±Ò¯Ò»Ñ–]*[Ð°ÐµÐ¸Ð¾ÑƒÑ‹ÑÑŽÑ]{3,}[^Ó™Ò“Ò›Ò£Ó©Ò±Ò¯Ò»Ñ–]*', re.IGNORECASE),  # Russian vowel patterns without Kazakh letters
    ]
    
    texts = [
        ("Ð‘Ò±Ð» Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ° Ó©Ñ‚Ðµ Ð¶Ð°Ò›ÑÑ‹, Ð¶Ñ‹Ð»Ð´Ð°Ð¼ Ð¶Ó™Ð½Ðµ Ñ‹Ò£Ò“Ð°Ð¹Ð»Ñ‹.", "kk"),  # Kazakh
        ("Ó¨Ñ‚Ðµ ÐºÐµÑ€ÐµÐ¼ÐµÑ‚ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°! Ð–Ò±Ð¼Ñ‹Ñ Ñ–ÑÑ‚ÐµÐ¹Ð´Ñ– Ñ‚Ð°Ð¼Ð°ÑˆÐ°.", "kk"),    # Kazakh
        ("Ð­Ñ‚Ð¾ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð¾Ñ‡ÐµÐ½ÑŒ Ñ…Ð¾Ñ€Ð¾ÑˆÐµÐµ, Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ðµ Ð¸ ÑƒÐ´Ð¾Ð±Ð½Ð¾Ðµ.", "ru"),  # Russian
        ("ÐžÑ‡ÐµÐ½ÑŒ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚! Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ°Ð¼.", "ru"),     # Russian
        ("Ð–Ð°Ò›ÑÑ‹ Ð°Ò›ÑˆÐ° Ò¯Ð½ÐµÐ¼Ð´ÐµÐ¹Ñ‚Ñ–Ð½ Ò›Ð¾ÑÑ‹Ð¼ÑˆÐ°. Ò°ÑÑ‹Ð½Ð°Ð¼Ñ‹Ð½!", "kk"),      # Kazakh
    ]
    
    def detect_kazakh_enhanced(text):
        kazakh_score = 0
        russian_score = 0
        
        # Count Kazakh patterns
        for pattern in kazakh_patterns:
            matches = len(pattern.findall(text))
            kazakh_score += matches
        
        # Count Russian patterns  
        for pattern in russian_patterns:
            matches = len(pattern.findall(text))
            russian_score += matches
        
        # Normalize by text length
        text_len = len(text.split())
        kazakh_norm = kazakh_score / text_len if text_len > 0 else 0
        russian_norm = russian_score / text_len if text_len > 0 else 0
        
        if kazakh_norm > russian_norm and kazakh_score > 0:
            return 'kk', kazakh_norm
        elif russian_norm > kazakh_norm and russian_score > 0:
            return 'ru', russian_norm  
        else:
            return 'unknown', 0
    
    correct = 0
    total = len(texts)
    
    for text, expected in texts:
        detected, score = detect_kazakh_enhanced(text)
        is_correct = detected == expected
        if is_correct:
            correct += 1
        
        status = "âœ“" if is_correct else "âœ—"
        logger.info(f"  {status} '{text[:40]}...' â†’ {detected} ({score:.2f}) [expected: {expected}]")
    
    accuracy = (correct / total * 100) if total > 0 else 0
    logger.info(f"\nEnhanced Kazakh patterns accuracy: {correct}/{total} ({accuracy:.1f}%)")
    
    return accuracy > 80

def main():
    """Test all available language detection libraries for Kazakh"""
    
    logger.info("ðŸ‡°ðŸ‡¿ Testing Kazakh Language Detection Alternatives")
    logger.info("="*60)
    
    # Test all available libraries
    results = {}
    
    results['langdetect'] = test_langdetect()
    results['polyglot'] = test_polyglot() 
    results['langid'] = test_langid()
    results['textblob'] = test_textblob()
    results['googletrans'] = test_googletrans()
    results['fasttext'] = test_fasttext()
    results['spacy'] = test_spacy()
    results['enhanced_patterns'] = test_enhanced_patterns()
    
    # Summary
    logger.info("\n" + "="*60)
    logger.info("SUMMARY OF ALTERNATIVES")
    logger.info("="*60)
    
    available_libs = [lib for lib, available in results.items() if available]
    logger.info(f"ðŸ“š Available libraries: {len(available_libs)}")
    for lib in available_libs:
        logger.info(f"  âœ“ {lib}")
    
    unavailable_libs = [lib for lib, available in results.items() if not available]
    if unavailable_libs:
        logger.info(f"\nâŒ Unavailable libraries: {len(unavailable_libs)}")
        for lib in unavailable_libs:
            logger.info(f"  âœ— {lib}")
    
    logger.info(f"\nðŸŽ¯ Recommendations for Kazakh detection:")
    logger.info(f"  1. Enhanced pattern-based detection (custom implementation)")
    logger.info(f"  2. FastText (if available) - supports 176 languages including Kazakh")
    logger.info(f"  3. Google Translate API (requires internet, but very accurate)")
    logger.info(f"  4. Combine multiple methods for better accuracy")
    
    return len(available_libs) > 0

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)